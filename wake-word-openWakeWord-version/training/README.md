# ğŸ§  Entrenamiento del Modelo "Puertocho"

Este directorio contiene todos los scripts y configuraciones necesarios para entrenar un modelo openWakeWord personalizado para la palabra "Puertocho".

## ğŸ¯ Objetivo

Entrenar un modelo de wake word especÃ­fico que elimine las detecciones mÃºltiples observadas con modelos genÃ©ricos y proporcione una palabra de activaciÃ³n Ãºnica.

## ğŸ“ Estructura del Proyecto

```
training/
â”œâ”€â”€ scripts/                          # Scripts de entrenamiento
â”‚   â”œâ”€â”€ setup_gcloud.sh              # ğŸš€ Configurar Google Cloud T4
â”‚   â”œâ”€â”€ setup_training_env.sh        # ğŸ§  Configurar entorno en Cloud
â”‚   â”œâ”€â”€ generate_positive_samples.py # ğŸ—£ï¸ Generar muestras "Puertocho"
â”‚   â”œâ”€â”€ download_negative_data.py    # ğŸ“¥ Descargar datos negativos
â”‚   â”œâ”€â”€ train_puertocho_model.py     # ğŸ§  Script principal entrenamiento
â”‚   â””â”€â”€ run_full_training_pipeline.sh # ğŸš€ Pipeline completo
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ training_config.yaml         # âš™ï¸ ConfiguraciÃ³n de entrenamiento
â”œâ”€â”€ data/                            # Datos de entrenamiento (generado)
â”‚   â”œâ”€â”€ positive/                    # Muestras "Puertocho"
â”‚   â””â”€â”€ negative/                    # Muestras ruido/otras palabras
â”œâ”€â”€ models/                          # Modelos entrenados (generado)
â”œâ”€â”€ logs/                            # Logs de entrenamiento (generado)
â””â”€â”€ README.md                        # Esta documentaciÃ³n
```

## ğŸš€ Inicio RÃ¡pido

### **OpciÃ³n 1: Pipeline AutomÃ¡tico (Recomendado)**

```bash
# En la instancia Google Cloud T4
cd ~/puertocho-training
./scripts/run_full_training_pipeline.sh
```

Este script ejecuta automÃ¡ticamente todo el proceso:
1. âœ… VerificaciÃ³n de prerrequisitos
2. ğŸ“Š GeneraciÃ³n de 2000 muestras positivas
3. ğŸ“¥ Descarga y procesamiento de datos negativos
4. âš–ï¸ AnÃ¡lisis de balance de datos
5. ğŸ§  Entrenamiento del modelo (3-6 horas)
6. ğŸ¯ ValidaciÃ³n y resumen final

### **OpciÃ³n 2: Paso a Paso**

#### **1. Configurar Google Cloud T4**
```bash
# En tu mÃ¡quina local
./scripts/setup_gcloud.sh tu-project-id
```

#### **2. Conectar y configurar entorno**
```bash
# Conectar a la instancia
gcloud compute ssh puertocho-training --zone=us-central1-a

# Configurar entorno
bash setup_training_env.sh
```

#### **3. Subir scripts de entrenamiento**
```bash
# En tu mÃ¡quina local
gcloud compute scp --recurse training/ puertocho-training:~/puertocho-training/ --zone=us-central1-a
```

#### **4. Generar datos positivos**
```bash
# En la instancia Cloud
python3 scripts/generate_positive_samples.py 2000
```

#### **5. Descargar datos negativos**
```bash
python3 scripts/download_negative_data.py
```

#### **6. Entrenar modelo**
```bash
python3 scripts/train_puertocho_model.py configs/training_config.yaml
```

## âš™ï¸ ConfiguraciÃ³n

### **Archivo de ConfiguraciÃ³n Principal**
`configs/training_config.yaml` contiene toda la configuraciÃ³n:

```yaml
model:
  name: "puertocho_v1"
  sample_rate: 16000
  frame_length: 1280

training:
  batch_size: 8          # Optimizado para T4
  learning_rate: 1e-4
  epochs: 100
  early_stopping_patience: 10

data:
  target_fpr: 0.5       # False positives por hora
  target_fnr: 0.05      # False negatives mÃ¡ximo
```

### **Variables de Entorno**
```bash
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH=$PYTHONPATH:~/puertocho-training
```

## ğŸ“Š Datos de Entrenamiento

### **Datos Positivos (Generados)**
- **Cantidad**: ~2000 muestras
- **Frases**: "Puertocho", "Hola Puertocho", "Oye Puertocho", etc.
- **Variaciones**: Velocidad, tono, ruido, voces
- **MÃ©todos TTS**: espeak, Festival, gTTS

### **Datos Negativos (Descargados/Generados)**
- **Common Voice espaÃ±ol**: ~8000 muestras
- **Ruido sintÃ©tico**: ~5000 muestras (blanco, rosa, marrÃ³n)
- **Palabras similares**: ~280 muestras ("Puerto", "Ocho", etc.)
- **Total**: ~13000+ muestras negativas

### **Balance de Datos**
- **Ratio recomendado**: 4:1 a 6:1 (negativo:positivo)
- **Ratio actual**: ~6.5:1
- **ValidaciÃ³n**: 20% de cada tipo

## ğŸ§  Proceso de Entrenamiento

### **Arquitectura del Modelo**
- **Tipo**: 1D CNN con caracterÃ­sticas mel-spectrogram
- **Input**: 1280 frames @ 16kHz (80ms)
- **Features**: 32 bandas mel
- **Output**: Probabilidad binaria (Puertocho vs No-Puertocho)

### **OptimizaciÃ³n**
- **Optimizador**: AdamW con weight decay
- **Loss**: Binary Cross Entropy con logits
- **Scheduler**: OneCycle con warmup
- **AMP**: Automatic Mixed Precision (T4)
- **Gradient Clipping**: Norm = 1.0

### **MÃ©tricas Objetivo**
- **Accuracy**: > 95%
- **False Positive Rate**: < 0.5/hora
- **False Negative Rate**: < 5%
- **F1 Score**: > 0.9

## ğŸ“ˆ Monitoreo

### **Durante el Entrenamiento**
```bash
# Monitor de sistema
./monitor_training.sh

# TensorBoard
tensorboard --logdir logs/tensorboard --host 0.0.0.0 --port 6006

# Logs en tiempo real
tail -f logs/training.log
```

### **URLs de Monitoreo**
- **Jupyter Lab**: `http://EXTERNAL_IP:8080`
- **TensorBoard**: `http://EXTERNAL_IP:6006`

## ğŸ¯ Resultados Esperados

### **Archivos Generados**
```
models/
â”œâ”€â”€ puertocho_v1_best.pth      # Mejor modelo PyTorch
â”œâ”€â”€ puertocho_v1.onnx          # Modelo para inferencia
â””â”€â”€ puertocho_v1_epoch_*.pth   # Checkpoints por Ã©poca

logs/
â”œâ”€â”€ training.log               # Log principal
â”œâ”€â”€ training_history_*.json    # MÃ©tricas de entrenamiento
â””â”€â”€ tensorboard/               # Logs TensorBoard
```

### **MÃ©tricas TÃ­picas**
```
Ã‰poca 45/100:
â”œâ”€â”€ Train Loss: 0.023456
â”œâ”€â”€ Train Acc: 98.2%
â”œâ”€â”€ Val Loss: 0.034567
â””â”€â”€ Val Acc: 96.8%

Early stopping: Sin mejora en 10 Ã©pocas
Mejor modelo: Ã‰poca 45 (Val Loss: 0.034567)
```

## ğŸš€ Deployment

### **1. Descargar Modelo**
```bash
# Desde la instancia Cloud a tu mÃ¡quina
gcloud compute scp puertocho-training:~/puertocho-training/models/puertocho_v1.onnx . --zone=us-central1-a
```

### **2. Subir a Raspberry Pi**
```bash
# A la Raspberry Pi
scp puertocho_v1.onnx pi@raspberry:/home/pi/puertocho-assistant-pi/wake-word-openWakeWord-version/checkpoints/
```

### **3. Actualizar ConfiguraciÃ³n**
```bash
# En la Raspberry Pi
echo "OPENWAKEWORD_MODEL_PATHS=/app/checkpoints/puertocho_v1.onnx" >> .env
echo "OPENWAKEWORD_THRESHOLD=0.75" >> .env
echo "OPENWAKEWORD_VAD_THRESHOLD=0.2" >> .env
```

### **4. Probar el Modelo**
```bash
# Reconstruir y probar
docker compose up --build
```

## ğŸ”§ Troubleshooting

### **Problemas Comunes**

#### **Error de Memoria GPU**
```bash
# Reducir batch size
sed -i 's/batch_size: 8/batch_size: 4/' configs/training_config.yaml
```

#### **Datos Insuficientes**
```bash
# Generar mÃ¡s muestras positivas
python3 scripts/generate_positive_samples.py 4000

# O mÃ¡s ruido sintÃ©tico
# Editar download_negative_data.py lÃ­nea: generate_synthetic_noise(10000)
```

#### **Convergencia Lenta**
```bash
# Aumentar learning rate
sed -i 's/learning_rate: 1e-4/learning_rate: 3e-4/' configs/training_config.yaml
```

#### **Overfitting**
```bash
# Aumentar dropout
sed -i 's/dropout: 0.3/dropout: 0.5/' configs/training_config.yaml
```

### **Logs de Debug**
```bash
# Ver logs completos
less logs/training_$(date +%Y%m%d)*.log

# Ãšltimas lÃ­neas de error
tail -50 logs/training.log

# MÃ©tricas de sistema
cat /proc/meminfo | grep Mem
nvidia-smi
```

## ğŸ’° GestiÃ³n de Costos

### **EstimaciÃ³n de Costos**
- **Instancia n1-standard-4**: $0.15/hora
- **GPU T4**: $0.35/hora
- **Almacenamiento 100GB**: ~$10/mes
- **Total entrenamiento**: ~$12-15

### **OptimizaciÃ³n de Costos**
```bash
# Parar instancia cuando no se use
gcloud compute instances stop puertocho-training --zone=us-central1-a

# Reanudar cuando necesites
gcloud compute instances start puertocho-training --zone=us-central1-a

# Eliminar al finalizar
gcloud compute instances delete puertocho-training --zone=us-central1-a
```

## ğŸ“ Notas Importantes

### **Antes de Entrenar**
- âœ… Verificar cuota de GPU T4 en Google Cloud
- âœ… Tener al menos $20 en crÃ©ditos
- âœ… Configurar firewall para puertos 8080 y 6006
- âœ… Hacer backup de configuraciones importantes

### **Durante el Entrenamiento**
- ğŸ”„ Monitorear GPU utilization (>80%)
- ğŸ“Š Verificar que loss disminuye
- â° Entrenamiento tÃ­pico: 3-6 horas
- ğŸ’¾ Checkpoints se guardan automÃ¡ticamente

### **DespuÃ©s del Entrenamiento**
- ğŸ“¤ Descargar modelo .onnx inmediatamente
- ğŸ—‘ï¸ Limpiar datos temporales grandes
- ğŸ’° Parar/eliminar instancia Cloud
- ğŸ§ª Probar modelo en Raspberry Pi

## ğŸ†˜ Soporte

### **Si algo sale mal:**
1. ğŸ“‹ Revisar logs completos
2. ğŸ” Verificar espacio en disco
3. ğŸ’¾ Verificar memoria GPU
4. ğŸŒ Verificar conectividad de red
5. ğŸ“– Consultar documentaciÃ³n openWakeWord

### **Recursos Adicionales**
- [openWakeWord Documentation](https://github.com/dscripka/openWakeWord)
- [Google Cloud GPU Guide](https://cloud.google.com/compute/docs/gpus)
- [PyTorch Mixed Precision](https://pytorch.org/docs/stable/amp.html)

---

## ğŸ‰ Â¡Ã‰xito!

Si todo va bien, tendrÃ¡s un modelo **"Puertocho"** personalizado que:
- âœ… Elimina detecciones mÃºltiples
- âœ… Responde solo a "Puertocho"
- âœ… Tiene threshold optimizado (0.75)
- âœ… Reduce false positives <0.5/hora
- âœ… Mantiene false negatives <5%

**Â¡Tu asistente de voz serÃ¡ Ãºnico y funcionarÃ¡ perfectamente!** ğŸš€ 