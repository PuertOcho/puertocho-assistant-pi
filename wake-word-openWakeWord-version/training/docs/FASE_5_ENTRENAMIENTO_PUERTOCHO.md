# ğŸ§  Fase 5: Entrenamiento del Modelo Personalizado "Puertocho"

## ğŸ¯ **Objetivo**

Entrenar un modelo openWakeWord personalizado para la palabra "Puertocho" que elimine definitivamente las detecciones mÃºltiples y false positives observados con modelos genÃ©ricos.

## ğŸ“Š **Estado Actual vs Objetivo**

### âŒ **Problema Actual (openWakeWord genÃ©rico)**
```
ğŸ¯ Wake word detectada: 'alexa' (score: 0.669)
ğŸ¯ Wake word detectada: 'alexa' (score: 0.995)  â† 8s despuÃ©s  
ğŸ¯ Wake word detectada: 'alexa' (score: 0.771)  â† Otra vez
```

### âœ… **Objetivo con "Puertocho" personalizado**
```
ğŸ¯ Wake word detectada: 'puertocho' (score: 0.85)
ğŸ‘‚ Listo para nueva wake word...
[Sin detecciones mÃºltiples - threshold optimizado para palabra especÃ­fica]
```

## ğŸ”§ **Estrategia de Entrenamiento**

### **OpciÃ³n 1: Google Cloud GPU T4 (Recomendada)**
Basada en experiencia exitosa con ChatterboxTTS y Porcupine.

**Ventajas:**
- âœ… Control total del entorno
- âœ… GPU T4 optimizada para ML
- âœ… Sin limitaciones de tiempo
- âœ… Costo predecible (~$10-15)

### **OpciÃ³n 2: Google Colab (Alternativa)**
Solo si la OpciÃ³n 1 no estÃ¡ disponible.

**Limitaciones:**
- âš ï¸ Sesiones de 12h mÃ¡ximo
- âš ï¸ Puede desconectarse
- âš ï¸ GPU compartida

## ğŸ“ **Plan de EjecuciÃ³n Detallado**

### ğŸ”– **Mapa del Proyecto, Datasets y Scripts Clave**

```text
training/
â”œâ”€â”€ data/                      # Se crea automÃ¡ticamente por los scripts
â”‚   â”œâ”€â”€ positive/              # WAV positivos (wake-word "Puertocho")
â”‚   â””â”€â”€ negative/              # WAV negativos/ruido (Common Voice + ruido sintÃ©tico)
â”œâ”€â”€ models/                    # Modelos resultantes (.onnx, .pth) + threshold
â”œâ”€â”€ logs/                      # Historial de mÃ©tricas y TensorBoard
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ training_config.yaml   # HiperparÃ¡metros y rutas de datasets
â””â”€â”€ scripts/
    â”œâ”€â”€ run_full_training_pipeline.sh   # Orquestador 100 % automÃ¡tico ğŸ”„
    â”œâ”€â”€ generate_positive_samples.py    # Genera positivos vÃ­a TTS (Coqui-TTS/espeak)
    â”œâ”€â”€ download_negative_data.py       # Descarga + filtra Common Voice ES
    â”œâ”€â”€ train_puertocho_model.py        # Entrenamiento PyTorch/openWakeWord
    â””â”€â”€ setup_training_env.sh           # Instala dependencias CUDA/OWW
```

### ğŸ“‚ **Convenciones de Nombres y Versionado de Datos**

| Conjunto      | Ejemplo de nombre de archivo                                   | DescripciÃ³n |
|---------------|---------------------------------------------------------------|-------------|
| Positivos     | `pos_puertocho_female-es_Maria_180wpm_0.9vol_0123.wav`        | `pos_` prefijo + palabra clave + metadatos TTS + Ã­ndice secuencial |
| Negativos     | `neg_cv-es_spk-0471_clip-875462.wav`                           | `neg_` prefijo + CommonVoice speaker + id de clip |
| Ruido sint.   | `neg_noise_white_-5dB_0042.wav`                                | Ruido blanco/rosa/marrÃ³n a distintos SNR |

*Cada script genera un `metadata.csv` en la carpeta correspondiente con las columnas `filepath,duration_sec,label,source,extra_tags` para trazabilidad.*

**Versionado & Backup**

1. Tras generar o actualizar datos, el pipeline crea un archivo comprimido `dataset_v<YYYYMMDD>.tar.gz`.
2. El snapshot se sube automÃ¡ticamente al bucket **`gs://puertocho-datasets/`**:
   * `gs://puertocho-datasets/positive/v<date>/...`
   * `gs://puertocho-datasets/negative/v<date>/...`
3. De igual forma, los modelos se publican en `gs://puertocho-datasets/models/` con nombre `puertocho_v<version>.onnx` y un archivo `threshold.txt` que contiene el umbral sugerido por la validaciÃ³n.

### âš¡ **EjecuciÃ³n Express**

```bash
# (Dentro de la instancia GPU ya configurada)
cd ~/training
bash scripts/run_full_training_pipeline.sh \
    --positive_count 2000 \
    --negative_lang es \
    --gcs_bucket gs://puertocho-datasets \
    --model_version v1
```

Este comando:
1. âœ… Valida dependencias y crea/actualiza `data/`.
2. ğŸ—£ï¸ Genera los WAV positivos (si no existen) usando `generate_positive_samples.py`.
3. ğŸ“¥ Descarga y recorta Common Voice ES (0.5-1.5 s) con `download_negative_data.py`.
4. ğŸ§¹ Balancea el dataset y actualiza `metadata.csv`.
5. ğŸ§  Lanza `train_puertocho_model.py` con `configs/training_config.yaml`.
6. ğŸ¯ Calcula FPR/FNR Ã³ptimos y escribe `models/puertocho_v1_threshold.txt`.
7. â˜ï¸ Sincroniza `/data` y `/models` al bucket GCS especificado.

> Nota: Todos los parÃ¡metros anteriores se pueden omitir; el script usa valores por defecto definidos al inicio.

### **Paso 1: PreparaciÃ³n del Dataset**

#### **1.1 Datos Positivos ("Puertocho")**
```bash
# Generar ~2000 variaciones usando TTS
"Puertocho"
"Hola Puertocho"  
"Oye Puertocho"
"Hey Puertocho"
"Activa Puertocho"
```

**Variaciones necesarias:**
- ğŸ—£ï¸ **Voces**: Masculina, femenina, diferentes acentos
- ğŸšï¸ **Velocidades**: Lenta, normal, rÃ¡pida
- ğŸ”Š **VolÃºmenes**: Bajo, normal, alto
- ğŸ­ **Estilos**: Formal, casual, susurro

#### **1.2 Datos Negativos (Ruido)**
```bash
# Descargar dataset de ruido (~30,000 horas)
- Conversaciones en espaÃ±ol
- Ruido ambiente
- MÃºsica
- TV/Radio
- Palabras similares: "Puerto", "Ocho", "Macho", etc.
```

### **Paso 2: ConfiguraciÃ³n del Entorno Cloud**

#### **2.1 Google Cloud Setup**
```bash
# Crear instancia optimizada
gcloud compute instances create puertocho-training \
    --zone=us-central1-a \
    --machine-type=n1-standard-4 \
    --accelerator=type=nvidia-tesla-t4,count=1 \
    --image-family=pytorch-latest-gpu \
    --image-project=deeplearning-platform-release \
    --boot-disk-size=100GB \
    --metadata="install-nvidia-driver=True"
```

#### **2.2 Dependencias**
```bash
# En la instancia Cloud
pip install openwakeword[training]
pip install torch torchaudio
pip install numpy scipy librosa
pip install wandb  # Para monitoreo
pip install tqdm
```

### **Paso 3: GeneraciÃ³n de Datos SintÃ©ticos**

#### **3.1 Script de TTS**
```python
import pyttsx3
import os
from pathlib import Path

def generate_puertocho_samples():
    """Generar muestras sintÃ©ticas de 'Puertocho'"""
    
    # Configurar TTS
    engine = pyttsx3.init()
    
    # Diferentes voces y configuraciones
    voices = engine.getProperty('voices')
    rates = [150, 180, 220]  # Velocidades
    volumes = [0.7, 0.9, 1.0]  # VolÃºmenes
    
    phrases = [
        "Puertocho",
        "Hola Puertocho", 
        "Oye Puertocho",
        "Hey Puertocho"
    ]
    
    output_dir = Path("positive_samples")
    output_dir.mkdir(exist_ok=True)
    
    sample_count = 0
    for phrase in phrases:
        for voice in voices[:2]:  # Usar 2 voces
            for rate in rates:
                for volume in volumes:
                    # Configurar voz
                    engine.setProperty('voice', voice.id)
                    engine.setProperty('rate', rate)
                    engine.setProperty('volume', volume)
                    
                    # Generar archivo
                    filename = f"puertocho_{sample_count:04d}.wav"
                    filepath = output_dir / filename
                    
                    engine.save_to_file(phrase, str(filepath))
                    engine.runAndWait()
                    
                    sample_count += 1
                    if sample_count >= 2000:
                        return
    
    print(f"Generadas {sample_count} muestras positivas")
```

#### **3.2 Descarga de Datos Negativos**
```bash
# Usar dataset Common Voice en espaÃ±ol
wget https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-13.0-2023-03-09/cv-corpus-13.0-2023-03-09-es.tar.gz

# Extraer y procesar
tar -xzf cv-corpus-13.0-2023-03-09-es.tar.gz
```

### **Paso 4: Entrenamiento del Modelo**

#### **4.1 ConfiguraciÃ³n de Entrenamiento**
```python
# training_config.yaml
model:
  name: "puertocho_v1"
  architecture: "mel_stft_1d_cnn"
  
training:
  batch_size: 8  # Optimizado para T4
  learning_rate: 1e-4
  epochs: 100
  early_stopping_patience: 10
  
data:
  sample_rate: 16000
  frame_length: 1280  # 80ms
  positive_samples_dir: "./positive_samples"
  negative_samples_dir: "./negative_samples"
  
optimization:
  target_fpr: 0.5  # False positives por hora
  target_fnr: 0.05  # 5% false negatives mÃ¡ximo
```

#### **4.2 Script de Entrenamiento**
```python
import openwakeword.train as oww_train

# Configurar entrenamiento
config = oww_train.load_config("training_config.yaml")

# Preparar datasets
train_loader, val_loader = oww_train.prepare_datasets(config)

# Entrenar modelo
model = oww_train.train_model(
    config=config,
    train_loader=train_loader,
    val_loader=val_loader,
    device="cuda"  # GPU T4
)

# Exportar modelo entrenado
oww_train.export_model(model, "puertocho_v1.onnx")
```

### **Paso 5: ValidaciÃ³n y Pruebas**

#### **5.1 MÃ©tricas Objetivo**
```python
# Validar rendimiento
test_results = oww_train.evaluate_model(
    model_path="puertocho_v1.onnx",
    test_dataset=test_loader
)

print(f"Accuracy: {test_results['accuracy']:.3f}")
print(f"False Positive Rate: {test_results['fpr']:.3f}/hora")
print(f"False Negative Rate: {test_results['fnr']:.3f}")

# Objetivos:
# - Accuracy > 0.95
# - FPR < 0.5/hora
# - FNR < 0.05
```

#### **5.2 Prueba en Raspberry Pi**
```bash
# Copiar modelo entrenado
scp puertocho_v1.onnx pi@raspberry:/home/pi/checkpoints/

# Actualizar configuraciÃ³n
echo "OPENWAKEWORD_MODEL_PATHS=/app/checkpoints/puertocho_v1.onnx" >> .env
echo "OPENWAKEWORD_THRESHOLD=0.75" >> .env  # Threshold optimizado
```

### **Paso 6: IntegraciÃ³n y OptimizaciÃ³n**

#### **6.1 Actualizar main.py**
```python
# En _setup_openwakeword()
model_paths_env = os.getenv('OPENWAKEWORD_MODEL_PATHS', '').strip()

if model_paths_env and 'puertocho' in model_paths_env:
    # Usar modelo personalizado
    model_kwargs['wakeword_models'] = [model_paths_env]
    print(f"ğŸ§  Usando modelo personalizado: {model_paths_env}")
else:
    # Fallback a modelos preentrenados
    print("ğŸ§  Usando modelos preentrenados")
```

#### **6.2 ConfiguraciÃ³n Optimizada**
```bash
# .env para modelo Puertocho
OPENWAKEWORD_MODEL_PATHS=checkpoints/puertocho_v1.onnx
OPENWAKEWORD_THRESHOLD=0.75  # MÃ¡s alto para menos false positives
OPENWAKEWORD_VAD_THRESHOLD=0.2  # Activar VAD para filtrar ruido
OPENWAKEWORD_ENABLE_SPEEX_NS=true  # SupresiÃ³n de ruido
```

## ğŸ“Š **Cronograma Estimado**

| Fase | DuraciÃ³n | DescripciÃ³n |
|------|----------|-------------|
| **Setup Cloud** | 1-2 horas | Configurar instancia T4 |
| **GeneraciÃ³n TTS** | 2-3 horas | Crear 2000 muestras positivas |
| **Dataset Negativo** | 1-2 horas | Descargar y procesar Common Voice |
| **Entrenamiento** | 3-6 horas | Entrenar modelo en GPU T4 |
| **ValidaciÃ³n** | 1 hora | Probar mÃ©tricas |
| **IntegraciÃ³n** | 1 hora | Integrar en Raspberry Pi |
| ****TOTAL** | **9-15 horas** | **Proyecto completo** |

## ğŸ’° **Costo Estimado**

### **Google Cloud T4**
- **Instancia**: n1-standard-4 = $0.15/hora
- **GPU T4**: $0.35/hora  
- **Almacenamiento**: 100GB = $10/mes
- **Total**: ~$12-15 para proyecto completo

### **Beneficio vs Costo**
- âœ… **Elimina detecciones mÃºltiples** definitivamente
- âœ… **Wake word personalizada** exclusiva
- âœ… **Threshold optimizado** para caso especÃ­fico
- âœ… **SoluciÃ³n permanente** vs parches temporales

## ğŸš€ **PrÃ³ximos Pasos**

1. **Decidir plataforma**: Â¿Google Cloud T4 o Colab?
2. **Configurar entorno** de entrenamiento
3. **Generar datasets** (positivos + negativos)
4. **Entrenar modelo** "Puertocho"
5. **Validar y optimizar** threshold
6. **Integrar en RPi** y probar

## â“ **Â¿Listo para comenzar?**

El modelo personalizado "Puertocho" resolverÃ¡ definitivamente el problema de detecciones mÃºltiples y proporcionarÃ¡ una wake word Ãºnica para tu asistente.

Â¿Prefieres empezar con **Google Cloud T4** (mÃ¡s control) o **Google Colab** (gratis pero limitado)? 