#!/usr/bin/env python3
"""
ğŸ¤ Asistente Puertocho con Modelo Personalizado
Usa directamente nuestro modelo ONNX entrenado
"""

import os
import time
import queue
import threading
import numpy as np
import sounddevice as sd
import onnxruntime as ort
from pathlib import Path

class PuertochoAssistant:
    def __init__(self):
        self.model_path = Path('checkpoints/puertocho.onnx')
        self.threshold = 0.5
        self.sample_rate = 16000
        self.chunk_size = 1280  # 80ms chunks
        self.audio_buffer = []
        self.running = False
        
        # Cargar modelo ONNX
        print(f"ğŸ¯ Cargando modelo Puertocho desde {self.model_path}")
        self.session = ort.InferenceSession(str(self.model_path))
        print("âœ… Modelo cargado exitosamente")
        
        # Buffer para audio
        self.audio_queue = queue.Queue()
        
    def audio_callback(self, indata, frames, time, status):
        """Callback para captura de audio"""
        if status:
            print(f"âš ï¸ Audio status: {status}")
        
        # Convertir a mono si es estÃ©reo
        if len(indata.shape) > 1:
            audio_data = indata[:, 0]
        else:
            audio_data = indata.flatten()
            
        self.audio_queue.put(audio_data)
    
    def process_audio(self):
        """Procesar audio en tiempo real"""
        print("ğŸ¤ Iniciando procesamiento de audio...")
        
        while self.running:
            try:
                # Obtener chunk de audio
                chunk = self.audio_queue.get(timeout=1.0)
                
                # AÃ±adir al buffer
                self.audio_buffer.extend(chunk)
                
                # Mantener buffer de 1 segundo (16000 samples)
                if len(self.audio_buffer) >= 16000:
                    # Tomar Ãºltimos 16000 samples
                    audio_window = np.array(self.audio_buffer[-16000:], dtype=np.float32)
                    
                    # Preparar input para el modelo
                    model_input = audio_window.reshape(1, -1)
                    
                    # Ejecutar inferencia
                    result = self.session.run(None, {'audio': model_input})
                    score = result[0][0][0]
                    
                    # Aplicar sigmoid para obtener probabilidad
                    probability = 1 / (1 + np.exp(-score))
                    
                    # Verificar detecciÃ³n
                    if probability > self.threshold:
                        print(f"ğŸ‰ Â¡PUERTOCHO DETECTADO! Probabilidad: {probability:.3f}")
                        self.on_wake_word_detected()
                    
                    # Mostrar estado cada cierto tiempo
                    if len(self.audio_buffer) % (16000 * 5) == 0:  # Cada 5 segundos
                        print(f"ğŸ”Š Escuchando... Ãšltima probabilidad: {probability:.3f}")
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ Error procesando audio: {e}")
    
    def on_wake_word_detected(self):
        """AcciÃ³n cuando se detecta la wake word"""
        print("ğŸ—£ï¸ Â¡Hola! Soy Puertocho. Â¿En quÃ© puedo ayudarte?")
        # AquÃ­ se puede integrar con el resto del sistema
        
    def start(self):
        """Iniciar el asistente"""
        print("ğŸš€ Iniciando Asistente Puertocho...")
        print(f"ğŸ“Š Threshold: {self.threshold}")
        print(f"ğŸµ Sample rate: {self.sample_rate} Hz")
        print("ğŸ’¡ Di 'Puertocho' para activar el asistente")
        print("ğŸ›‘ Presiona Ctrl+C para salir")
        
        self.running = True
        
        # Iniciar hilo de procesamiento
        process_thread = threading.Thread(target=self.process_audio)
        process_thread.daemon = True
        process_thread.start()
        
        # Iniciar captura de audio
        try:
            with sd.InputStream(
                callback=self.audio_callback,
                channels=1,
                samplerate=self.sample_rate,
                blocksize=self.chunk_size,
                dtype=np.float32
            ):
                print("ğŸ¤ Escuchando...")
                while self.running:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print("\nğŸ›‘ Deteniendo asistente...")
            self.running = False
        except Exception as e:
            print(f"âŒ Error en captura de audio: {e}")
            self.running = False

if __name__ == "__main__":
    assistant = PuertochoAssistant()
    assistant.start()
