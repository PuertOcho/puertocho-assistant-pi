# üìù STATUS_QUO.md

> **Fecha de actualizaci√≥n:** 2025-07-03
>
> Este documento resume el estado **actual** del proyecto *Puertocho Voice-Assistant*, cubriendo avance funcional, infraestructura, configuraciones clave y pr√≥ximos pasos.

---

## 1. Visi√≥n general

El asistente funciona en Raspberry Pi con `openWakeWord` para la detecci√≥n de palabra clave. Tras problemas de *false-positives* con modelos gen√©ricos ("alexa"), se decidi√≥ entrenar un modelo personalizado **"Puertocho"**. Las fases 1-4 se han completado; la Fase 5 (entrenamiento) est√° en curso con una instancia GPU en Google Cloud.

---

## 2. Progreso por Fase

| Fase | Descripci√≥n | Estado |
|------|-------------|--------|
| 1 | Preparaci√≥n del entorno | ‚úÖ Completada |
| 2 | Integraci√≥n b√°sica `openWakeWord` | ‚úÖ Completada |
| 3 | Integraci√≥n con l√≥gica del asistente | ‚úÖ Completada |
| 4 | Optimizaci√≥n & robustez | ‚úÖ Completada (penden subtareas menores de optimizaci√≥n) |
| 5 | Entrenamiento modelo "Puertocho" | üîÑ En progreso |
| 6 | Validaci√≥n & despliegue | ‚è≥ Pendiente |
| 7 | Mejoras avanzadas | ‚è≥ Pendiente |

---

## 3. TODOs activos

| ID | Tarea | Estado | Dependencias |
|----|-------|--------|--------------|
| generate_positive_samples | Generar ~2000 muestras positivas v√≠a TTS | pending | setup_training_environment |
| download_negative_dataset | Descargar/limpiar Common Voice ES | pending | setup_training_environment |
| train_puertocho_model | Entrenar modelo personalizado | pending | generate_positive_samples,<br/>download_negative_dataset |
| validate_model_performance | Validar m√©tricas del modelo | pending | train_puertocho_model |
| integrate_custom_model | Integrar modelo en RPi & ajustar threshold | pending | validate_model_performance |
| integrate_user_samples | Integrar 103 muestras grabadas por el usuario | completed | generate_positive_samples |

*Nota:* Todos los elementos de Fases 1-4 y los test automatizados aparecen como **completed** en el tracker.

---

## 4. Configuraci√≥n actual en Raspberry Pi

| Par√°metro | Valor |
|-----------|-------|
| `OPENWAKEWORD_THRESHOLD` | **0.6** |
| Cool-down detecci√≥n | **8 s** (implementado en `app/main.py`) |
| Modelos activos* | `alexa`, `hey_mycroft`‚Ä† |
| VAD | Deshabilitado (`threshold=0.0`) |
| Speex Noise Suppression | `false` |
| Inference framework | `onnx` |
| Audio | 16 kHz, 1 canal, 1280 samples (80 ms) |
| GPIO | Bot√≥n 22, LED verde 17 (IDLE), LED rojo 27 (RECORD) |

\* Se espera reemplazarlos por `checkpoints/puertocho.onnx` cuando el modelo est√© listo.

‚Ä† Wake-words gen√©ricas empleadas s√≥lo para pruebas temporales.

### Servicios & Scripts relevantes

- `scripts/monitor_performance.py` ‚Üí m√©tricas CPU/GPU, temperatura, RAM.
- `scripts/auto_optimizer.py` ‚Üí auto-ajuste de par√°metros (`threshold`, VAD, etc.) seg√∫n m√©tricas.
- Docker Compose con `network_mode: host` y dispositivos ALSA/GPIO expuestos.

---

## 5. Infraestructura Google Cloud

| Recurso | Valor |
|---------|-------|
| **Proyecto GCP** | `puertocho-wakeword-training` |
| **Billing Account** | `01D005-255612-3CCE8D` (vinculada) |
| **Cuota GPU T4** | 1 unidad global (aprobada) |

### Instancias activas (03-Jul-2025)

| Nombre | Zona | Tipo m√°quina | GPU | Disco | Estado | Creaci√≥n |
|--------|------|--------------|-----|-------|--------|----------|
| `puertocho-training` | us-central1-b | `g2-standard-4` | 1√ó NVIDIA L4 | 100 GB NVMe | **RUNNING** | 2025-07-03 07:38 UTC |

Detalles adicionales de la VM:

- **Imagen base:** *Deep Learning VM* PyTorch 2.4 CUDA 12.4 (Debian 11)
- **Drivers NVIDIA:** instalados autom√°ticamente (`install-nvidia-driver=True`).
- **IP externa:** `34.61.242.82` (puertos 22, 8080, 6006 abiertos).
- **Etiquetas:** `deeplearning-vm`.

> üí∞ **Costo aproximado:** USD 0.596 / h (`g2-standard-4` + 1 L4 GPU @ us-central1-b).

---

## 6. Entorno de entrenamiento

- Carpeta **`training/`** con scripts y configuraci√≥n detallada.
- Config principal: `configs/training_config.yaml` (batch_size 8, lr 1e-4, epochs 100, AMP = true, target FPR 0.5 / h).
- Pipeline autom√°tico: `scripts/run_full_training_pipeline.sh`.
- Datos objetivo: 2000 positivos, ‚â•10 000 negativos ‚Üí ratio ~6:1.

---

## 7. Pr√≥ximas acciones clave

1. **Generar muestras positivas** en la VM (`generate_positive_samples.py`).
2. **Descargar dataset negativo** (`download_negative_data.py`).
3. **Ejecutar entrenamiento** (`train_puertocho_model.py`) y validar m√©tricas.
4. **Exportar modelo ONNX** y **subirlo a la Raspberry Pi**.
5. Ajustar `OPENWAKEWORD_THRESHOLD` (‚âà0.5-0.8) con pruebas reales.
6. Actualizar `PROJECT_TRACKER.md` y cerrar TODOs correspondientes.

---

## 8. Enlaces √∫tiles

- Documentaci√≥n entrenamiento: `training/README.md`, `docs/FASE_5_ENTRENAMIENTO_PUERTOCHO.md`
- openWakeWord Repo: <https://github.com/dscripka/openWakeWord>
- Google Cloud GPUs: <https://cloud.google.com/compute/docs/gpus>

---

> Fin del reporte. Mantener este archivo actualizado conforme avance el proyecto. 